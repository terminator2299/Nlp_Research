# RAG Using FAISS

This repository demonstrates a simple **Retrieval-Augmented Generation (RAG)** pipeline using **FAISS** for document retrieval, **SentenceTransformers** for embeddings, and **T5/GPT** for answer generation.

## ğŸ“Œ Project Flow
1. **Retrieve relevant documents** â†’ FAISS/Elasticsearch.
2. **Embed documents & query** â†’ SentenceTransformers (`sentence-transformers/all-mpnet-base-v2`).
3. **Generate an answer** â†’ T5/GPT with retrieved content as context.

## ğŸ“ File Structure
```
RagUsing_FAISS/
â”‚â”€â”€ data/                      # Folder for storing documents
â”‚   â”œâ”€â”€ sample.txt             # Example document
â”‚â”€â”€ index/                     # FAISS index storage
â”‚â”€â”€ scripts/
â”‚   â”œâ”€â”€ embed.py               # Script to embed and store documents in FAISS
â”‚   â”œâ”€â”€ retrieve.py            # Script to retrieve documents from FAISS
â”‚   â”œâ”€â”€ generate.py            # Script to generate answers using T5/GPT
â”‚â”€â”€ requirements.txt           # Dependencies
â”‚â”€â”€ README.md                  # Project documentation
```

## ğŸš€ Installation
1. **Clone the repository:**
   ```sh
   git clone https://github.com/your-repo/RagUsing_FAISS.git
   cd RagUsing_FAISS
   ```

2. **Create a virtual environment (optional but recommended):**
   ```sh
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```sh
   pip install -r requirements.txt
   ```

## ğŸ”§ Usage
### 1ï¸âƒ£ **Indexing Documents**
Run the `embed.py` script to embed and store documents in FAISS.
```sh
python scripts/embed.py
```

### 2ï¸âƒ£ **Retrieving Documents**
Run `retrieve.py` to fetch relevant documents based on a query.
```sh
python scripts/retrieve.py --query "What is FAISS?"
```

### 3ï¸âƒ£ **Generating Answers**
Use `generate.py` to generate an answer based on retrieved content.
```sh
python scripts/generate.py --query "What is FAISS?"
```

## ğŸ›  Dependencies
- `faiss-cpu`
- `sentence-transformers`
- `transformers`
- `torch`
- `datasets`
- `numpy`
- `tqdm`

Install them manually if needed:
```sh
pip install faiss-cpu sentence-transformers transformers torch datasets numpy tqdm
```

## ğŸ“ Notes
- The model used for embedding is `sentence-transformers/all-mpnet-base-v2`.
- You can replace `T5` with `GPT` or another LLM for better response generation.
- Modify `data/sample.txt` to add your own dataset.

## ğŸ“Œ To-Do
âœ… Basic retrieval using FAISS
âœ… Query embedding and retrieval
â¬œï¸ Optimize retrieval quality
â¬œï¸ Improve answer generation with fine-tuned LLMs

---
ğŸš€ **Contributions & feedback are welcome!**

